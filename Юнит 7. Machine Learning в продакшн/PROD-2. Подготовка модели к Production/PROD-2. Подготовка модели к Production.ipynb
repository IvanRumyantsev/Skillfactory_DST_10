{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('base': conda)",
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 6. Бинарные файлы: Pickle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ЭТАП 1\n",
    "\n",
    "Обучим модель линейной регрессии на встроенном датасете Diabetes dataset. Опустим кросс-валидацию и разделение выборки на обучение и тест, так как для наших целей это не важно."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X,y)"
   ]
  },
  {
   "source": [
    "Объект regressor теперь является обученной моделью. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ЭТАП 2\n",
    "\n",
    "Импортируем модуль и воспользуемся методом dumps:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(bytes, sklearn.linear_model._base.LinearRegression)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pickle\n",
    "model = pickle.dumps(regressor)\n",
    "type(model), type(regressor)"
   ]
  },
  {
   "source": [
    "Как видим, мы создали объект model типа bytes. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ЭТАП 3\n",
    "\n",
    "Восстановим объект Python:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "regressor_from_bytes = pickle.loads(model)\n",
    "regressor_from_bytes"
   ]
  },
  {
   "source": [
    "## ЭТАП 4\n",
    "Сохраним объект в файл"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('myfile.pkl', 'wb') as output:\n",
    "       pickle.dump(regressor, output)"
   ]
  },
  {
   "source": [
    "Теперь у нас есть бинарный файл с готовой моделью."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ЭТАП 5\n",
    "\n",
    "Файл myfile.pkl так же легко десериализовать:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "with open('myfile.pkl', 'rb') as pkl_file:\n",
    "    regressor_from_file = pickle.load(pkl_file)\n",
    "\n",
    "regressor_from_file"
   ]
  },
  {
   "source": [
    "## ЭТАП 6\n",
    "Убедимся, что методы и результаты предсказаний обученной модели и загруженной из файла совпадают:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "all(regressor.predict(X) == regressor_from_bytes.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "all(regressor.predict(X) == regressor_from_file.predict(X))"
   ]
  },
  {
   "source": [
    "## ОГРАНИЧЕНИЯ\n",
    "\n",
    "Как мы упоминали, у Pickle есть ограничения. Например, мы не сможем сериализовать лямбда-функции. Давайте посмотрим, что нам вернёт следующий код:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x0000024A1348A4C8>: attribute lookup <lambda> on __main__ failed",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-70cbd6285ecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmy_lambda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_lambda.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_lambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x0000024A1348A4C8>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "my_lambda = lambda x: x*2\n",
    "with open('my_lambda.pkl', 'wb') as output:\n",
    "    pickle.dump(my_lambda, output)"
   ]
  },
  {
   "source": [
    "### Совет. В таких случаях лучше пользоваться пакетом [dill](https://github.com/uqfoundation/dill)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Задание 6.1\n",
    "\n",
    "Что делает метод dumps из библиотеки Pickle?\n",
    "\n",
    "- позволяет сохранить сериализованный объект в файл\n",
    "- возвращает сериализованный объект верно\n",
    "- загружает объект из файла и десериализует его\n",
    "- загружает объект из потока байт"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Задание 6.2\n",
    "Что делает метод load из библиотеки Pickle?\n",
    "\n",
    "- позволяет сохранить сериализованный объект в файл\n",
    "- возвращает сериализованный объект\n",
    "- загружает объект из файла и десериализует его верно\n",
    "- загружает объект из потока байт"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 7. Сохранение пайплайна\n",
    "\n",
    "Мы уже упоминали, что Pickle работает с любыми объектами Python. Поэтому для сохранения может быть доступна не просто обученная модель, но и целый пайплайн, включающий предобработку данных. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "pipe = Pipeline([  \n",
    "  ('Scaling', MinMaxScaler()),\n",
    "  ('FeatureSelection', SelectKBest(f_regression, k=5)),\n",
    "  ('Linear', LinearRegression())\n",
    "  ])\n",
    "\n",
    "\n",
    "pipe.fit(X, y)\n",
    "pipe.predict(X[1:2])\n",
    "s1 = pickle.dumps(pipe)\n",
    "pipe_from_bytes = pickle.loads(s1)\n",
    "\n",
    "print(all(pipe.predict(X) == pipe_from_bytes.predict(X)))"
   ]
  },
  {
   "source": [
    "Задание 7.1\n",
    "Что выдаст этот код?\n",
    "\n",
    "True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Обратите внимание, что для работы с файлами используются методы pickle.dump и pickle.load, а для работы с сериализованными объектами pickle.dumps и pickle.loads.\n",
    "\n",
    "Как мы видим, Pickle прекрасно справляется со своей задачей, однако иногда массивы данных бывают настолько большими, что после загрузки из Pickle можно не восстановить объект полностью. \n",
    "\n",
    "В таких случаях лучше использовать Joblib вместо Pickle. Этот модуль более эффективен для объектов, которые содержат большие массивы данных. Он оптимизирован для быстрой и надежной работы с данными большого объема. Пожалуй, единственный минус этого модуля в том, что он может «консервировать» только в файл, поэтому вы не сможете получить объект в виде бинарной строки и работать с ним. В модуле попросту отсутствуют методы для работы с бинарной строкой."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Для иллюстрации работы сохраним обученную модель:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['regr.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(regressor, 'regr.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#…и загрузим его заново:\n",
    "clf_from_jobliv = load('regr.joblib') \n",
    "all(regressor.predict(X) == clf_from_jobliv.predict(X))"
   ]
  },
  {
   "source": [
    "# 8. Практика: Pickle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ЗАДАНИЕ 1\n",
    "Коллега обучил модель и теперь просит вас проверить её на ваших данных. Он присылает вам Pickle-файл. Загрузите модель, используя модуль Pickle. (hw1.pkl)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Вопрос 8.1\n",
    "При загрузке вывелся секретный код. Введите его в поле ниже."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "secret word: skillfactory\nhow is this possible? answer is here: https://youtu.be/xm-A-h9QkXg\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "with open('hw1.pkl', 'rb') as pkl_file:\n",
    "    secret_model = pickle.load(pkl_file)\n",
    "secret_model"
   ]
  },
  {
   "source": [
    "## Вопрос 8.2\n",
    "\n",
    "Проверьте, какого типа объект получился. Введите название библиотеки, которую использовал ваш коллега."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sklearn.linear_model._base.LinearRegression"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "type(secret_model)"
   ]
  },
  {
   "source": [
    "Ответ: sklearn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Вопрос 8.3\n",
    "\n",
    "Теперь вам нужно применить модель. Сделайте предсказание для этого набора фичей: \n",
    "\\[1, 1, 1, 0.661212487096872]'. Введите результат (округлите до тысячных, например 0.853)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1, 1, 1, 0.661212487096872]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.666])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "secret_model.predict(X)"
   ]
  },
  {
   "source": [
    "## ЗАДАНИЕ 2\n",
    "\n",
    "У модели есть два поля с именами a и b. Создайте из них словарь с такими же именами ключей и значениями, а затем сохраните в файл с помощью модуля Pickle. \n",
    "\n",
    "Проверить, что вы всё сделали правильно, можно с помощью скрипта."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python hw1_check_ol.py mydict.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'a':secret_model.a, 'b':secret_model.b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_dict.pkl', 'wb') as output:\n",
    "       pickle.dump(my_dict, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('secret code 2:', '3c508')\n"
     ]
    }
   ],
   "source": [
    "!python hw1_check_ol.py my_dict.pkl"
   ]
  },
  {
   "source": [
    "# 9. Форматы PMML и ONNX-ML"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting nyoka==4.2.1\n  Downloading nyoka-4.2.1-py3-none-any.whl (331 kB)\nRequirement already satisfied: lxml in d:\\anaconda3\\lib\\site-packages (from nyoka==4.2.1) (4.5.2)\nInstalling collected packages: nyoka\nSuccessfully installed nyoka-4.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nyoka==4.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyoka import skl_to_pmml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "cols = load_diabetes()['feature_names']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "pipe = Pipeline([  \n",
    "            ('Scaling', MinMaxScaler()),\n",
    "            ('Linear', LinearRegression())\n",
    "        ])\n",
    "# Тренировка пайплайна, включающего линейную модель и нормализацию признаков\n",
    "pipe.fit(X, y)\n",
    "# Сохраним пайплайн в формате pmml в файл pipe.pmml\n",
    "skl_to_pmml(pipeline=pipe, col_names=cols, pmml_f_name=\"pipe.pmml\")"
   ]
  },
  {
   "source": [
    "## *Задание для продвинутых (необязательно, но рекомендуется)\n",
    "\n",
    "Для выполнения этого задания вам понадобится ознакомиться с документацией.\n",
    "\n",
    "В задаче ниже мы обучаем модель sklearn, конвертируем ее в ONNX и делаем инференс через ONNX-runtime.\n",
    "\n",
    "Дополните код ниже недостающими элементами:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'get_all_providers' from 'onnxruntime.capi._pybind_state' (D:\\Anaconda3\\lib\\site-packages\\onnxruntime\\capi\\_pybind_state.py)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-b21c2793c05d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_boston\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#from skl2onnx import ___1____\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\onnxruntime\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0m__author__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Microsoft\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pybind_state\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_all_providers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_available_providers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mRunOptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSessionOptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_default_logger_severity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNodeArg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelMetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGraphOptimizationLevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mExecutionMode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOrtDevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSessionIOBinding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_all_providers' from 'onnxruntime.capi._pybind_state' (D:\\Anaconda3\\lib\\site-packages\\onnxruntime\\capi\\_pybind_state.py)"
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from skl2onnx import ___1____\n",
    "\n",
    "#from skl2onnx.common.data_types import ___2___\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# загружаем данные\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# обучаем модель\n",
    "model = LinearRegression()\n",
    "#model.fit(___3___, y_train)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# делаем инференс моделью на тесте\n",
    "#test_pred = model.predict(___4___)\n",
    "test_pred = model.predict(X_test)\n",
    "print('sklearn model predict:\\n', test_pred)\n",
    "\n",
    "# конвертируем модель в onnx формат\n",
    "# initial_type = [('float_input', ___5___([None, ___6___]))]\n",
    "initial_type = [('float_input', FloatTensorType([None, 10]))]\n",
    "\n",
    "#model_onnx = ___7___(model, initial_types=initial_type)\n",
    "model_onnx = convert_sklearn(model, initial_types=initial_type)\n",
    "\n",
    "# сохраняем модель в файл\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "\tf.write(model_onnx.SerializeToString())\n",
    " \t \n",
    "# Делаем инференс на тесте через onnxruntime\n",
    "#sess = rt.___8___(\"model.onnx\")\n",
    "sess = rt.InferenceSession(\"model.onnx\")\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "test_pred_onnx = sess.run([label_name],\n",
    "                \t{input_name:  X_test.astype(np.float32)})[0].reshape(-1)\n",
    "print('onnx model predict:\\n',test_pred_onnx) "
   ]
  }
 ]
}